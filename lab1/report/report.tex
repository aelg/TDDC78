\documentclass[a4paper,11pt]{article}
%\documentclass[a4paper,9pt,landscape]{article}
\usepackage[english,swedish]{babel}
%\usepackage[utf8]{inputenc}
\usepackage{graphicx}
\usepackage{fullpage}
\usepackage{amsmath}
\usepackage{pdfpages}
\usepackage{listings}
\usepackage{color}
\usepackage{multicol}
\usepackage{fancyhdr}
\usepackage[top=1.5cm, bottom=4cm, left=2.5cm, right=2.5cm]{geometry}
\usepackage{hyperref}
\setlength{\voffset}{-9pt}
%\setlength{\hoffset}{-1in}
%\setlength{\marginparsep}{0.5cm}


\setlength{\parindent}{1cm}
%\setlength{\parskip}{-0.1cm}
%\setlength{\columnseprule}{0.4pt}
\setlength{\footskip}{0.5cm}
\setlength{\headheight}{15pt}
\setlength{\headsep}{2cm}

\fancypagestyle{tcr}{%
  \fancyhf{} %clear all headers and footers fields
  \fancyhead[R]{\thepage}
  \fancyhead[L]{\textbf{Lab No 1 TDDC78}}
  \renewcommand{\headrulewidth}{0.4pt}
}

\definecolor{dkgreen}{rgb}{0,0.6,0}
\definecolor{gray}{rgb}{0.5,0.5,0.5}
\definecolor{mauve}{rgb}{0.58,0,0.82}
\lstset{
  title=\lstname,
  frame=t,
  aboveskip=-0.5cm, 
  belowskip=0pt,
  basicstyle=\footnotesize\ttfamily,
  keywordstyle=\color{blue},          % keyword style
  commentstyle=\color{dkgreen},       % comment style
  stringstyle=\color{mauve},         % string literal style
  showstringspaces=false,         % underline spaces within strings
  tabsize=2,
  language=C++,
  title=\caption,
  xleftmargin=-1cm
}


\begin{document}
%% title stuff
\title{Lab No 1 TDDC78}
\author{Linus Mellberg (linme560) \and Oskar Aagaard (oskaa489)}
\date{\today}
\maketitle
\pagebreak
%\setcounter{page}{1}
%\begin{multicols}{2}
\thispagestyle{tcr}
\pagestyle{tcr}
%\tableofcontents

\section{Averaging filter}
The averaging filter works by convoluting the input image with a gaussian filter kernel.
This will do a weighted average on the pixel and the pixels surrounding it.
Since the gaussian kernel is symmetric the the calculation can be simplified, this makes the problem linear in the radius of the kernel.
\subsection{Description of the program}
The program uses the MPI framework for communication between the processes.
Parallelization is done by splitting the picture into equal regions along the y-axis.
Each process then apply the filter on the region that is given to it. 
Since the filter does averaging on the neighbouring pixels each process needs more data than the pixels which it filters.
This makes it neccesary to send more data to each process than the data that belongs to the region which it filters.

The process with rank 0 reads the image from disk.
When this is done it broadcast the dimension of the picture.
Every process then calculates how the picture is divided into regions and shared between the processes.
When this is done the rank 0 process send the data to the processes, each process gets all data needed to do its own filtering.
As soon as a process has recieved its data it will start applying the filter to it.
The rank 0 thread also gets a region of the image and start processing as soon as possible, the send operations are non-blocking so this should occur fairly quickly.
When the processes are done eith the filtering a Gatherv operation is performed to collect all the data at the rank 0 process.
This process then writes the filtered image to disk.

\subsection{Result and graphs}
\section{Thresholding filter}
The thresholding filter turns a coloured image into a black and white image. A pixel in the filtered image is black if its colour intensity is lower than a threshold, otherwise white. The colour intensity is calculated by summing the RGB values of a pixel. The threshold is determined by the average colour intensity of all the pixels.
\subsection{Description of the program}
The first step is determining the average pixel intensity by adding the RGB values of each pixel in the image together and dividing by the total number of pixels. The program then looks at the RGB sum for each pixel in turn and determines if the corresponding pixel of the output image should be black or white by whether it's greater or lower than the average.

\paragraph\noindent\textbf{Overview of the linear program}
\begin{itemize}
\renewcommand{\labelitemi}{$\bullet$}
\item Load image from disk
\item Calculate average RGB sum
\item Calculate output image
\item Write image to disk
\end{itemize}

Because there is no dependency between pixels during either of the two calculations the work can easily be divided between an arbitrary amount of processors by giving them an as equal share as possible with no concern for locality. 

The program calculates the work share of each processor and then distributes the splitted source image by using the MPI\_Scatter command. The processors then calculate the RGB sum of their share and the total sum is then calculated and redistributed for the second calculation by using the MPI\_Allreduce command.

\paragraph\noindent\textbf{Overview of the parallel program}

\begin{itemize}
\renewcommand{\labelitemi}{$\bullet$}
\item Load image from disk on root processor
\item Calculate work shares
\item Use MPI\_Scatter to distribute parts of the image
\item Calculate average RGB sum in parallel
\item Sum the results and redistributed the total sum by using MPI\_Allreduce
\item Calculate output image in parallel
\item Gather the result to the root processor by using MPI\_Gather
\item Root process writes image to disk
\end{itemize}

\subsection{Result and graphs}
\begin{table}[h!]
  \label{entropitakt}
  \caption{Entropitakter beroende pmodellordning f testfilerna.}
  \begin{tabular}[h]{|l|l|l|l|l|l|l|l|l|l|}
    \hline
    Modellordning & 0     & 1     & 2     & 3     & 4     & 5     & 6     & 7     & 8\\
    \hline
    alice29.txt   & 4.568 & 3.419 & 2.485 & 1.777 & 1.324 & 0.978 & 0.724 & 0.522 & 0.371 \\ 
    asyoulik.txt  & 4.808 & 3.418 & 2.538 & 1.896 & 1.380 & 0.966 & 0.661 & 0.425 & 0.265 \\ 
    cp.html       & 5.229 & 3.467 & 1.738 & 0.774 & 0.443 & 0.328 & 0.266 & 0.229 & 0.197 \\ 
    fields.c      & 5.007 & 2.950 & 1.470 & 0.867 & 0.624 & 0.499 & 0.374 & 0.265 & 0.203 \\ 
    grammar.lsp   & 4.630 & 2.805 & 1.286 & 0.670 & 0.448 & 0.370 & 0.302 & 0.246 & 0.174 \\ 
    kennedy.xls   & 3.573 & 2.777 & 1.712 & 1.577 & 1.442 & 1.354 & 1.261 & 1.123 & 1.065 \\ 
    lcet10.txt    & 4.669 & 3.497 & 2.612 & 1.838 & 1.376 & 1.078 & 0.842 & 0.646 & 0.485 \\ 
    plrabn12.txt  & 4.531 & 3.366 & 2.717 & 2.138 & 1.729 & 1.377 & 1.047 & 0.742 & 0.487 \\ 
    ptt5          & 1.210 & 0.824 & 0.705 & 0.530 & 0.397 & 0.316 & 0.283 & 0.265 & 0.248 \\ 
    sum           & 5.329 & 3.298 & 1.931 & 1.199 & 0.740 & 0.540 & 0.448 & 0.338 & 0.199 \\ 
    xargs.1       & 4.897 & 3.194 & 1.549 & 0.727 & 0.427 & 0.279 & 0.196 & 0.158 & 0.124 \\ 
    bible.txt     & 4.343 & 3.269 & 2.479 & 1.911 & 1.576 & 1.369 & 1.201 & 1.045 & 0.890 \\ 
    E.coli        & 2.000 & 1.981 & 1.963 & 1.951 & 1.943 & 1.936 & 1.930 & 1.920 & 1.889 \\ 
    world192.txt  & 4.998 & 3.660 & 2.771 & 1.918 & 1.287 & 0.912 & 0.714 & 0.587 & 0.483 \\ 
    \hline
  \end{tabular}
\end{table}

\cite{fenwick}
\clearpage
\begin{thebibliography}{9}
  \bibitem{fenwick}
    Binary Indexed Trees,
    \emph{Algortihmist}.\\
    \url{http://community.topcoder.com/tc?module=Static\&d1=tutorials\&d2=binaryIndexedTrees}
  \bibitem{ppm}
    Mark Nelson,
    \emph{Arithmetic Coding + Statistical Modeling = Data Compression}, 1991.\\
    \url{http://marknelson.us/1991/02/01/arithmetic-coding-statistical-modeling-data-compression/}
  \bibitem{ppmc}
    PPM
    \url{http://www.cs.ucf.edu/courses/cap5015/ppm.pdf}

\end{thebibliography}

\clearpage
\section{KÃ¤llkod}
%
%\lstinputlisting[caption=entropy.cc]{../entropy.cc}
%\clearpage
%\lstinputlisting[caption=huffman.cc]{../huffman.cc}
%\clearpage
%\lstinputlisting[caption=arithmetic.cc]{../arithmetic.cc}
%\clearpage
%\lstinputlisting[caption=model.h]{../model.h}
%\clearpage
%\lstinputlisting[caption=model.cc]{../model.cc}
\end{document}
